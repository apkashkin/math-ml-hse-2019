{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение\n",
    "\n",
    "## Факультет математики НИУ ВШЭ\n",
    "\n",
    "### 2019-2020 учебный год\n",
    "\n",
    "Илья Щуров, Соня Дымченко, Руслан Хайдуров, Павел Балтабаев, Александр Каган"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 14\n",
    "\n",
    "На этом семинаре мы:\n",
    "\n",
    "- решим задачу классификации с помощью рекуррентной нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем датасет с именами и будем определять, из какого языка произошло данное имя. Для этого построим рекуррентную сеть, которая работает с именами на уровне символов. А именно, на вход сети подается набор символов (имя), и на каждом шаге на выходе из сети оказываются предсказание и скрытое состояние, которое используется на следующем шаге. Предсказание на последнем шаге будет браться за итоговое, то есть мы получим прогноз сети, к какому классу принадлежит данное имя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка для скачивания: https://download.pytorch.org/tutorial/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-23 12:13:54--  https://download.pytorch.org/tutorial/data.zip\n",
      "Resolving download.pytorch.org (download.pytorch.org)... 13.32.43.113, 13.32.43.91, 13.32.43.52, ...\n",
      "Connecting to download.pytorch.org (download.pytorch.org)|13.32.43.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2882130 (2.7M) [application/zip]\n",
      "Saving to: 'data.zip'\n",
      "\n",
      "data.zip            100%[===================>]   2.75M   513KB/s    in 8.8s    \n",
      "\n",
      "2020-04-23 12:14:03 (322 KB/s) - 'data.zip' saved [2882130/2882130]\n",
      "\n",
      "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "! wget https://download.pytorch.org/tutorial/data.zip -O data.zip && unzip -qq ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mArabic.txt\u001b[m\u001b[m     \u001b[31mEnglish.txt\u001b[m\u001b[m    \u001b[31mIrish.txt\u001b[m\u001b[m      \u001b[31mPolish.txt\u001b[m\u001b[m     \u001b[31mSpanish.txt\u001b[m\u001b[m\r\n",
      "\u001b[31mChinese.txt\u001b[m\u001b[m    \u001b[31mFrench.txt\u001b[m\u001b[m     \u001b[31mItalian.txt\u001b[m\u001b[m    \u001b[31mPortuguese.txt\u001b[m\u001b[m \u001b[31mVietnamese.txt\u001b[m\u001b[m\r\n",
      "\u001b[31mCzech.txt\u001b[m\u001b[m      \u001b[31mGerman.txt\u001b[m\u001b[m     \u001b[31mJapanese.txt\u001b[m\u001b[m   \u001b[31mRussian.txt\u001b[m\u001b[m\r\n",
      "\u001b[31mDutch.txt\u001b[m\u001b[m      \u001b[31mGreek.txt\u001b[m\u001b[m      \u001b[31mKorean.txt\u001b[m\u001b[m     \u001b[31mScottish.txt\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls ./data/names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала приведем текстовые файлы с именами к удобному формату, так, что на выходе получится словарь язык-список имен. В код можно особо не вникать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n",
      "['Arabic.txt', 'Chinese.txt', 'Czech.txt', 'Dutch.txt', 'English.txt', 'French.txt', 'German.txt', 'Greek.txt', 'Irish.txt', 'Italian.txt', 'Japanese.txt', 'Korean.txt', 'Polish.txt', 'Portuguese.txt', 'Russian.txt', 'Scottish.txt', 'Spanish.txt', 'Vietnamese.txt']\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "names_path = 'data/names/'\n",
    "\n",
    "print(os.listdir(names_path))\n",
    "\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in os.listdir(names_path):\n",
    "    category = filename.split('.')[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(names_path + filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hung' 'Kwang ' 'Choi' 'Bang' 'Chong' 'Baik' 'Shin']\n",
      "['Zheltyannikov' 'Hludov' 'Bezyzvestnykh' 'Pelih' 'Isayan' 'Tsvetov'\n",
      " 'Ablyazov']\n"
     ]
    }
   ],
   "source": [
    "print(np.random.choice(category_lines['Korean'], size=7, replace=False))\n",
    "print(np.random.choice(category_lines['Russian'], size=7, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конвертируем имена в тензоры для того, чтобы их можно было подать на вход сети. Для этого векторизуем каждую букву бинарным вектором из нулей и единиц с 1 на позиции, соответствующей индексу буквы в алфавите. Например, `\"c\" -> (0 0 1 0 0 ...)`. Таким образом, имя превратится в тензор размера `количество символов x величина батча x количество букв в алфавите`. В данном случае будем использовать 1 батч, букв в алфавите всего 57, поэтому итоговая размерность будет `количество символов x 1 x 57`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --user torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters.index(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdata\u001b[m\u001b[m              data.zip          sem14_texts.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! unzip ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.index(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    # (づ｡◕‿‿◕｡)づ\n",
    "    result = torch.zeros(1, len(all_letters))\n",
    "    result[:, letterToIndex(letter)] = 1\n",
    "    return result\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    # (づ｡◕‿‿◕｡)づ\n",
    "    result = [letterToTensor(letter) for letter in line]\n",
    "    result = torch.cat(result)\n",
    "    return result[:, None, :]\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i.imgur.com/Z2xbySO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем простейшую однослойную RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), dim=1)\n",
    "        # (づ｡◕‿‿◕｡)づ\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.softmax(self.i2o(combined))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # (づ｡◕‿‿◕｡)づ\n",
    "        return torch.zeros(self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что все корректно работает: выходы классификатора должны быть лог-вероятностями (чем больше, тем вероятнее категория)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = letterToTensor('A')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0169, -2.8755, -2.8750, -2.8206, -2.8922, -2.9890, -2.9230, -2.8624,\n",
      "         -2.8993, -2.8175, -2.9090, -2.9377, -2.8596, -3.0155, -2.7862, -2.7726,\n",
      "         -2.8698, -2.9477]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)\n",
    "print(torch.exp(output).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы интерпретировать выход модели, напишем функцию, переводящую лог-вероятности в категорию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0169, -2.8755, -2.8750, -2.8206, -2.8922, -2.9890, -2.9230, -2.8624,\n",
       "         -2.8993, -2.8175, -2.9090, -2.9377, -2.8596, -3.0155, -2.7862, -2.7726,\n",
       "         -2.8698, -2.9477]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scottish', 15)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для получения случайного объекта из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Scottish / line = Robertson\n",
      "category = Portuguese / line = Guerra\n",
      "category = Chinese / line = Wei\n",
      "category = Spanish / line = Lobo\n",
      "category = English / line = Schofield\n",
      "category = Vietnamese / line = Dam\n",
      "category = Korean / line = Ngai\n",
      "category = Italian / line = Tosto\n",
      "category = Irish / line = Patrick\n",
      "category = English / line = Crofts\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдем непосредственно к обучению. Для этого напишем функцию, в ходе которой:\n",
    "\n",
    "- на вход поступают объект (имя) и класс (язык)\n",
    "- инициализируются скрытые состояния (нулями)\n",
    "- forward-pass: считывается каждый символ и скрытое состояние для него сохраняется для следующего символа\n",
    "- считается итоговое предсказание\n",
    "- считается значение функции потерь (loss)\n",
    "- backward-pass и обновление весов\n",
    "- возвращаются loss и качество предсказания (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(category, category_tensor, line_tensor, optimizer):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.shape[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = F.nll_loss(output, category_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    acc = (categoryFromOutput(output)[0] == category)\n",
    "\n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим построенную модель на случайных объектах из обучающей выборки и построим графики значений функции потерь и качества. На каждом тысячном шагу будем ставить отметку, соответствующую среднему значению на предыдущих `1000` объектах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling matplotlib-3.2.1:\n",
      "  Successfully uninstalled matplotlib-3.2.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cbook' has no attribute '_suppress_matplotlib_deprecation_warning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-85c67995044c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;31m# this is the instance used by the matplotlib classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m \u001b[0mrcParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrc_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36mrc_params\u001b[0;34m(fail_on_error)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrc_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfail_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;34m\"\"\"Construct a `RcParams` instance from the default Matplotlib rc file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrc_params_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfail_on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36mrc_params_from_file\u001b[0;34m(fname, fail_on_error, use_default_template)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0miter_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_suppress_matplotlib_deprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         config = RcParams([(key, default) for key, (default, _) in iter_params\n\u001b[1;32m    992\u001b[0m                            if key not in _all_deprecated])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.cbook' has no attribute '_suppress_matplotlib_deprecation_warning'"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n_iters = 50000\n",
    "plot_every = 1000\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "current_acc = 0\n",
    "all_accs = []\n",
    "\n",
    "n_hidden = 128\n",
    "\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "opt = torch.optim.RMSprop(rnn.parameters(), lr=0.001)\n",
    "for iter in trange(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    loss, acc = train(category, category_tensor, line_tensor, opt)\n",
    "    current_loss += loss\n",
    "    current_acc += acc\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0\n",
    "        all_accs.append(current_acc / plot_every)\n",
    "        current_acc = 0\n",
    "\n",
    "        \n",
    "plt.figure()\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(range(plot_every, n_iters + 1, plot_every), all_losses)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(range(plot_every, n_iters + 1, plot_every), all_accs)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/77/a37c8877474f3b75dfe18f490189243d39aabd6c7629ffde5e5512d070fd/matplotlib-3.2.1-cp36-cp36m-macosx_10_9_x86_64.whl (12.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.5MB 1.5MB/s ta 0:00:011  60% |███████████████████▌            | 7.6MB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement not upgraded as not directly required: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/sgord1/anaconda3/lib/python3.6/site-packages (from matplotlib) (2.2.2)\n",
      "Requirement not upgraded as not directly required: kiwisolver>=1.0.1 in /Users/sgord1/anaconda3/lib/python3.6/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement not upgraded as not directly required: numpy>=1.11 in /Users/sgord1/anaconda3/lib/python3.6/site-packages (from matplotlib) (1.14.5)\n",
      "Requirement not upgraded as not directly required: cycler>=0.10 in /Users/sgord1/anaconda3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement not upgraded as not directly required: python-dateutil>=2.1 in /Users/sgord1/anaconda3/lib/python3.6/site-packages (from matplotlib) (2.7.3)\n",
      "Requirement not upgraded as not directly required: setuptools in /Users/sgord1/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
      "Requirement not upgraded as not directly required: six in /Users/sgord1/anaconda3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.11.0)\n",
      "Installing collected packages: matplotlib\n",
      "Successfully installed matplotlib-3.2.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --user --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказание сети для `10000` случайных объектов. Для визуализации результата построим матрицу ошибок для языков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 10000\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время поэкспериментировать с предсказаниями!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line, n_predictions=5):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line))\n",
    "\n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])\n",
    "\n",
    "predict('Hinton')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- измените параметр `learning_rate` внутри оптимизатора. Что происходит, когда он слишком большой? А слишком маленький?\n",
    "\n",
    "- добавьте больше слоев!\n",
    "\n",
    "- решите эту же задачу с помощью LSTM и GRU блоков (`nn.LSTM`, `nn.GRU`)\n",
    "\n",
    "- **(*)** постройте более сложные модели на основе уже испробованных - например, двусторонние (bidirectional) LSTM и GRU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
